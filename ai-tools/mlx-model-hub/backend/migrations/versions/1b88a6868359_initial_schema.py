"""initial_schema

Revision ID: 1b88a6868359
Revises: 
Create Date: 2026-01-11 14:18:19.209308

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel.sql.sqltypes


# revision identifiers, used by Alembic.
revision: str = '1b88a6868359'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('datasets',
    sa.Column('name', sqlmodel.sql.sqltypes.AutoString(length=255), nullable=False),
    sa.Column('path', sqlmodel.sql.sqltypes.AutoString(length=1000), nullable=False),
    sa.Column('checksum', sqlmodel.sql.sqltypes.AutoString(length=64), nullable=False),
    sa.Column('schema_info', sa.JSON(), nullable=True),
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('datasets', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_datasets_name'), ['name'], unique=True)

    op.create_table('models',
    sa.Column('name', sqlmodel.sql.sqltypes.AutoString(length=255), nullable=False),
    sa.Column('task_type', sa.Enum('TEXT_GENERATION', 'CLASSIFICATION', 'SUMMARIZATION', 'QUESTION_ANSWERING', 'CHAT', name='tasktype'), nullable=False),
    sa.Column('description', sqlmodel.sql.sqltypes.AutoString(length=2000), nullable=True),
    sa.Column('base_model', sqlmodel.sql.sqltypes.AutoString(length=500), nullable=False),
    sa.Column('tags', sa.JSON(), nullable=True),
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('mlflow_experiment_id', sqlmodel.sql.sqltypes.AutoString(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('models', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_models_name'), ['name'], unique=True)

    op.create_table('model_versions',
    sa.Column('version', sqlmodel.sql.sqltypes.AutoString(length=50), nullable=False),
    sa.Column('status', sa.Enum('TRAINING', 'READY', 'ARCHIVED', 'FAILED', name='modelversionstatus'), nullable=False),
    sa.Column('metrics', sa.JSON(), nullable=True),
    sa.Column('artifact_path', sqlmodel.sql.sqltypes.AutoString(length=1000), nullable=True),
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('model_id', sa.Uuid(), nullable=False),
    sa.Column('mlflow_run_id', sqlmodel.sql.sqltypes.AutoString(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['model_id'], ['models.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('model_versions', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_model_versions_model_id'), ['model_id'], unique=False)

    op.create_table('training_jobs',
    sa.Column('status', sa.Enum('QUEUED', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', name='jobstatus'), nullable=False),
    sa.Column('config', sa.JSON(), nullable=True),
    sa.Column('error_message', sqlmodel.sql.sqltypes.AutoString(length=5000), nullable=True),
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('model_id', sa.Uuid(), nullable=False),
    sa.Column('dataset_id', sa.Uuid(), nullable=False),
    sa.Column('model_version_id', sa.Uuid(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('heartbeat_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['model_id'], ['models.id'], ),
    sa.ForeignKeyConstraint(['model_version_id'], ['model_versions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('training_jobs', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_training_jobs_dataset_id'), ['dataset_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_training_jobs_model_id'), ['model_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_training_jobs_status'), ['status'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('training_jobs', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_training_jobs_status'))
        batch_op.drop_index(batch_op.f('ix_training_jobs_model_id'))
        batch_op.drop_index(batch_op.f('ix_training_jobs_dataset_id'))

    op.drop_table('training_jobs')
    with op.batch_alter_table('model_versions', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_model_versions_model_id'))

    op.drop_table('model_versions')
    with op.batch_alter_table('models', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_models_name'))

    op.drop_table('models')
    with op.batch_alter_table('datasets', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_datasets_name'))

    op.drop_table('datasets')
    # ### end Alembic commands ###
