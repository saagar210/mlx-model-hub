[
    {
        "id": "mlx-community/Llama-4-Scout-17B-16E-Instruct-4bit",
        "name": "Llama 4 Scout 17B (4-bit)",
        "size": "10.5GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-4-Scout-17B-16E-Instruct-4bit"
    },
    {
        "id": "mlx-community/Llama-3.3-70B-Instruct-4bit",
        "name": "Llama 3.3 70B Instruct (4-bit)",
        "size": "40.0GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.3-70B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Gemma-3-4b-it-4bit",
        "name": "Gemma 3 4B Instruct (4-bit)",
        "size": "2.8GB",
        "family": "Gemma",
        "url": "https://huggingface.co/mlx-community/Gemma-3-4b-it-4bit"
    },
    {
        "id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "name": "TinyLlama 1.1B (Chat)",
        "size": "2.0GB",
        "family": "Llama",
        "url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    },
    {
        "id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
        "name": "Llama 3.2 1B Instruct (4-bit)",
        "size": "0.65GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.2-1B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Llama-3.2-1B-Instruct-8bit",
        "name": "Llama 3.2 1B Instruct (8-bit)",
        "size": "1.2GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.2-1B-Instruct-8bit"
    },
    {
        "id": "mlx-community/Llama-3.2-1B-Instruct-bf16",
        "name": "Llama 3.2 1B Instruct (bf16)",
        "size": "2.3GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.2-1B-Instruct-bf16"
    },
    {
        "id": "mlx-community/Llama-3.2-3B-Instruct-4bit",
        "name": "Llama 3.2 3B Instruct (4-bit)",
        "size": "1.7GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Llama-3.2-3B-Instruct-8bit",
        "name": "Llama 3.2 3B Instruct (8-bit)",
        "size": "3.2GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-8bit"
    },
    {
        "id": "mlx-community/Llama-3.2-3B-Instruct-bf16",
        "name": "Llama 3.2 3B Instruct (bf16)",
        "size": "6.0GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-bf16"
    },
    {
        "id": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
        "name": "Llama 3.1 8B Instruct (4-bit)",
        "size": "4.2GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Meta-Llama-3.1-8B-Instruct-8bit",
        "name": "Llama 3.1 8B Instruct (8-bit)",
        "size": "7.9GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-Instruct-8bit"
    },
    {
        "id": "mlx-community/Meta-Llama-3.1-70B-Instruct-4bit",
        "name": "Llama 3.1 70B Instruct (4-bit)",
        "size": "37.0GB",
        "family": "Llama",
        "url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-70B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-0.5B-Instruct-4bit",
        "name": "Qwen 2.5 0.5B Instruct (4-bit)",
        "size": "0.26GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-0.5B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-1.5B-Instruct-4bit",
        "name": "Qwen 2.5 1.5B Instruct (4-bit)",
        "size": "0.81GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-1.5B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-3B-Instruct-4bit",
        "name": "Qwen 2.5 3B Instruct (4-bit)",
        "size": "1.6GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-3B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-3B-Instruct-8bit",
        "name": "Qwen 2.5 3B Instruct (8-bit)",
        "size": "3.1GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-3B-Instruct-8bit"
    },
    {
        "id": "mlx-community/Qwen2.5-3B-Instruct-bf16",
        "name": "Qwen 2.5 3B Instruct (bf16)",
        "size": "5.7GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-3B-Instruct-bf16"
    },
    {
        "id": "mlx-community/Qwen2.5-7B-Instruct-4bit",
        "name": "Qwen 2.5 7B Instruct (4-bit)",
        "size": "4.0GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-7B-Instruct-8bit",
        "name": "Qwen 2.5 7B Instruct (8-bit)",
        "size": "7.5GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-8bit"
    },
    {
        "id": "mlx-community/Qwen2.5-14B-Instruct-4bit",
        "name": "Qwen 2.5 14B Instruct (4-bit)",
        "size": "7.7GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-32B-Instruct-4bit",
        "name": "Qwen 2.5 32B Instruct (4-bit)",
        "size": "17.2GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-32B-Instruct-4bit"
    },
    {
        "id": "mlx-community/Qwen2.5-72B-Instruct-4bit",
        "name": "Qwen 2.5 72B Instruct (4-bit)",
        "size": "38.1GB",
        "family": "Qwen",
        "url": "https://huggingface.co/mlx-community/Qwen2.5-72B-Instruct-4bit"
    },
    {
        "id": "mlx-community/gemma-2-2b-it-4bit",
        "name": "Gemma 2 2B Instruct (4-bit)",
        "size": "1.4GB",
        "family": "Gemma",
        "url": "https://huggingface.co/mlx-community/gemma-2-2b-it-4bit"
    },
    {
        "id": "mlx-community/gemma-2-2b-it-8bit",
        "name": "Gemma 2 2B Instruct (8-bit)",
        "size": "2.6GB",
        "family": "Gemma",
        "url": "https://huggingface.co/mlx-community/gemma-2-2b-it-8bit"
    },
    {
        "id": "mlx-community/gemma-2-9b-it-4bit",
        "name": "Gemma 2 9B Instruct (4-bit)",
        "size": "4.8GB",
        "family": "Gemma",
        "url": "https://huggingface.co/mlx-community/gemma-2-9b-it-4bit"
    },
    {
        "id": "mlx-community/gemma-2-9b-it-8bit",
        "name": "Gemma 2 9B Instruct (8-bit)",
        "size": "9.1GB",
        "family": "Gemma",
        "url": "https://huggingface.co/mlx-community/gemma-2-9b-it-8bit"
    },
    {
        "id": "mlx-community/gemma-2-27b-it-4bit",
        "name": "Gemma 2 27B Instruct (4-bit)",
        "size": "18.6GB",
        "family": "Gemma",
        "url": "https://huggingface.co/mlx-community/gemma-2-27b-it-4bit"
    },
    {
        "id": "mlx-community/Mistral-7B-Instruct-v0.3-4bit",
        "name": "Mistral 7B Instruct v0.3 (4-bit)",
        "size": "3.8GB",
        "family": "Mistral",
        "url": "https://huggingface.co/mlx-community/Mistral-7B-Instruct-v0.3-4bit"
    },
    {
        "id": "mlx-community/Mistral-7B-Instruct-v0.3-8bit",
        "name": "Mistral 7B Instruct v0.3 (8-bit)",
        "size": "7.2GB",
        "family": "Mistral",
        "url": "https://huggingface.co/mlx-community/Mistral-7B-Instruct-v0.3-8bit"
    },
    {
        "id": "mlx-community/Mixtral-8x7B-Instruct-v0.1-4bit",
        "name": "Mixtral 8x7B Instruct (4-bit)",
        "size": "24.5GB",
        "family": "Mistral",
        "url": "https://huggingface.co/mlx-community/Mixtral-8x7B-Instruct-v0.1-4bit"
    },
    {
        "id": "mlx-community/Mixtral-8x22B-Instruct-v0.1-4bit",
        "name": "Mixtral 8x22B Instruct (4-bit)",
        "size": "73.7GB",
        "family": "Mistral",
        "url": "https://huggingface.co/mlx-community/Mixtral-8x22B-Instruct-v0.1-4bit"
    },
    {
        "id": "mlx-community/Phi-3.5-mini-instruct-4bit",
        "name": "Phi 3.5 Mini Instruct (4-bit)",
        "size": "2.0GB",
        "family": "Phi",
        "url": "https://huggingface.co/mlx-community/Phi-3.5-mini-instruct-4bit"
    },
    {
        "id": "mlx-community/Phi-3.5-mini-instruct-8bit",
        "name": "Phi 3.5 Mini Instruct (8-bit)",
        "size": "3.8GB",
        "family": "Phi",
        "url": "https://huggingface.co/mlx-community/Phi-3.5-mini-instruct-8bit"
    },
    {
        "id": "mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit",
        "name": "DeepSeek Coder V2 Lite (4-bit)",
        "size": "8.2GB",
        "family": "DeepSeek",
        "url": "https://huggingface.co/mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit"
    },
    {
        "id": "mlx-community/DeepSeek-V3-4bit",
        "name": "DeepSeek V3 (4-bit)",
        "size": "351.7GB",
        "family": "DeepSeek",
        "url": "https://huggingface.co/mlx-community/DeepSeek-V3-4bit"
    },
    {
        "id": "ft-07335ddd-d91f-4f6e-96fc-2b835be5df9d",
        "name": "Test",
        "base_model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "adapter_path": "adapters/07335ddd-d91f-4f6e-96fc-2b835be5df9d",
        "size": "Adapter",
        "family": "Custom",
        "is_custom": true,
        "is_finetuned": true,
        "params": {
            "epochs": 3,
            "batch_size": 1,
            "lora_rank": 8,
            "lora_alpha": 16.0,
            "learning_rate": 0.0001,
            "max_seq_len": 512,
            "dropout": 0.0,
            "lora_layers": 8
        }
    }
]